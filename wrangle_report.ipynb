{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORTING: WRANGLE REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "The wrangling process is of three steps:\n",
    "\n",
    "-Gathering\n",
    "\n",
    "-Assessing\n",
    "\n",
    "-Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATHERING PROCESS\n",
    "The twitter-archive-enhanced.csv file was downloaded manually. This dataset contains columns such as tweet_id, source, text, expanded_urls, name, retweeted_status_id et al, timestamp, dog type info and in_reply_to_user_id. This was read into pandas as \"twitter_archive\" dataframe.\n",
    "\n",
    "Using tweepy python module to access the twitter API, the tweet ids in the twitter_archive-enhanced.csv file were used to access the tweets' json info. The info was then read into a txt file named tweet_json.txt. Info like tweet_id, retweet_count and like_count were then extracted from the entries in the text file and read into a pandas dataframe. This dataframe is named tweet_info.\n",
    "\n",
    "Using python's requests library, the image_predictions dataset was downloaded programmatically from a url given. This dataset contains a neural network's predictions of the dog breeds using the images contained in the tweet. The confindence level for each prediction was also contained in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSESSING\n",
    "\n",
    "#### VISUAL ASSESSMENT\n",
    "During visual assessment of the dataset, three quality issues and two tidiness issues were observed.\n",
    "The quality issues were: \n",
    "\n",
    "1. Null values in expanded_url column.\n",
    "\n",
    "2. image_predictions should be summarized into more useful columns for proper analysis.\n",
    "\n",
    "3. rating_denominator and rating_numerator was extracted improperly for some columns.\n",
    "\n",
    "The tidiness issues observed visually were:\n",
    "1. tweet_info dataframe should be merged to twitter_archive dataframe as they are the same observational unit.\n",
    "\n",
    "2. image_predictions dataframe should be merged to twitter_archive dataframe.\n",
    "\n",
    "#### PROGRAMMATIC ASSESSMENT\n",
    "During programmatic assessment using pandas' dataframe methods such as .info() and .head(), the following quality issues were identified:\n",
    "\n",
    "1. timestamp column should be datetime data type, not string\n",
    "\n",
    "2. tweets that are retweets should be removed from the dataframe\n",
    "\n",
    "3. some entries are not original tweets but replies to other tweets or comments\n",
    "\n",
    "4. columns such as retweeted_status_id, in_reply_to_status_id should be removed since they will only contain null values\n",
    "\n",
    "5. Incomplete data in image_predictions dataset (2075 entries instead of 2356)\n",
    "\n",
    "6. dog types should be category data type, tweet_id should be string not int.\n",
    "\n",
    "The tidiness issues were: \n",
    "1. columns 'pupper', 'doggo', 'floofer' and 'puppo' should be merged as one variable should be a column (not 4 as it is in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEANING PROCESS\n",
    "Copies of the dataset were first made so as to preserve the original information contained in the datset.\n",
    "The structural issues were tackled first as data wrangling rule of thumb.\n",
    "The multiple columns in the twitter_archive dataframe violates the rule of tidiness ('each variable must be a column'). To solve this problem, the four columns were merged using the .melt() function into two columns- types and dog_types. Using the .melt() function, many multiple rows will be created; this was also solved.\n",
    "\n",
    "The next issue tackled was the second tidiness issue: tweet_info dataset and twitter_archive dataset should be merged as each observational unit must form a table. This was solved using pd.merge().\n",
    "\n",
    "The tweets that are not original tweets (i.e retweets and replies) were then dropped from the dataset. Columns relating to the retweets and replies are now dropped since they are irrelevant to original tweets.\n",
    "\n",
    "Datatype issues were addressed next. Timestamp was changed to datetime datatype and dog_type column was changed to category datatype.\n",
    "\n",
    "The image_predictions dataset contains too much information that will not really be relevant to analysis. This was solved by creating two columns that properly summarize the info in the dataset. A function was created for this purpose; the model's (reliable) prediction of the dog breed and the model's prediction of whether the image is a dog or not. \n",
    "\n",
    "The new summarized image_predictions dataset was then merged with the twitter_archive dataset so as to solve the last tidiness issue.\n",
    "\n",
    "Some ratings were improperly extracted from the tweet's text. These columns were identified and corrected.\n",
    "\n",
    "The last datatype issue -tweet_id,  can now be corrected. And expanded_urls column can be dropped since it is irrelevant to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned dataset was then saved as a csv file named 'twitter_archive_master.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
